{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3324348,"sourceType":"datasetVersion","datasetId":576013}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport numpy as np\nimport pandas as pd\nimport os\n\n# With the toggle '+ Add Input' on the right, add the covid19-radiography-database dataset\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-27T16:49:52.073986Z","iopub.execute_input":"2025-11-27T16:49:52.074313Z","iopub.status.idle":"2025-11-27T16:51:15.418567Z","shell.execute_reply.started":"2025-11-27T16:49:52.074288Z","shell.execute_reply":"2025-11-27T16:51:15.417721Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python -c \"import monai\" || pip install -q \"monai-weekly[gdown, nibabel, tqdm, ignite]\"\n!python -c \"import matplotlib\" || pip install -q matplotlib\n%matplotlib inline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T16:51:15.419827Z","iopub.execute_input":"2025-11-27T16:51:15.420174Z","iopub.status.idle":"2025-11-27T16:52:33.067036Z","shell.execute_reply.started":"2025-11-27T16:51:15.420157Z","shell.execute_reply":"2025-11-27T16:52:33.066263Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Import dataset**","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\n\n# First define your BASE_DIR: this will be the base directory\n# in wich you will save your final model\nBASE_DIR = Path.cwd()\n\n# Since we are using Kaggle, define the correct path to problem data\ndataset_path = Path(\"/kaggle/input/covid19-radiography-database\")\ndataset_folder = \"COVID-19_Radiography_Dataset\"\n\n# Check how the directory is actually organized...\nimage_dir_names = #CODE\n\n# ...and finally extract data, filling dataset_files\ndataset_files = []\n\n#CODE\n#CODE\n#CODE\n#CODE\n\n\n# How many images do we have?\nprint(#CODE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T16:52:33.068054Z","iopub.execute_input":"2025-11-27T16:52:33.068327Z","iopub.status.idle":"2025-11-27T16:52:33.41271Z","shell.execute_reply.started":"2025-11-27T16:52:33.068303Z","shell.execute_reply":"2025-11-27T16:52:33.411971Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import math\n\n# Reduce the dimension of the dataset to work faster\nnew_size = #CODE\ndataset_files = #CODE\n\n# How many images do we have in the end?\nprint(#CODE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T16:52:33.413989Z","iopub.execute_input":"2025-11-27T16:52:33.414197Z","iopub.status.idle":"2025-11-27T16:52:34.450921Z","shell.execute_reply.started":"2025-11-27T16:52:33.414179Z","shell.execute_reply":"2025-11-27T16:52:34.450291Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Check shape of dataset_files","metadata":{}},{"cell_type":"code","source":"from PIL import Image\n\n# Before proceding, check whether images and masks have the same size\n\nimg = #CODE\nmask = #CODE\n\nprint(f\"image={img.size}, mask={mask.size}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T16:54:18.707534Z","iopub.execute_input":"2025-11-27T16:54:18.708032Z","iopub.status.idle":"2025-11-27T16:54:18.71966Z","shell.execute_reply.started":"2025-11-27T16:54:18.708007Z","shell.execute_reply":"2025-11-27T16:54:18.719039Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Plot image and mask**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Before developing any model, plot the images and masks\n\nimg = #CODE\nmask = #CODE\n\nplt.figure(figsize=(10,5))\n\nplt.subplot(1,2,1)\nplt.title(\"Image\")\nplt.imshow(img, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.subplot(1,2,2)\nplt.title(\"Mask\")\nplt.imshow(mask, cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T10:47:33.779225Z","iopub.execute_input":"2025-11-27T10:47:33.779543Z","iopub.status.idle":"2025-11-27T10:47:34.114165Z","shell.execute_reply.started":"2025-11-27T10:47:33.779523Z","shell.execute_reply":"2025-11-27T10:47:34.113513Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Dataset class**","metadata":{}},{"cell_type":"markdown","source":"### Now, implement the Dataset and DataLoader classes, which you will use along the project","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\n# This will be your Dataset class\nclass SegmentationDataset(Dataset):\n    # Initialization of the Dataset\n    def __init__(self, data, transform=None):\n        #CODE\n        #CODE\n\n    def __len__(self):\n        #CODE\n\n    def __getitem__(self, idx):\n        #CODE\n        #CODE\n        #CODE\n        #CODE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T10:47:34.121Z","iopub.execute_input":"2025-11-27T10:47:34.121259Z","iopub.status.idle":"2025-11-27T10:47:35.770817Z","shell.execute_reply.started":"2025-11-27T10:47:34.121236Z","shell.execute_reply":"2025-11-27T10:47:35.770249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This will be your DataLoader class.\n# (Actually, we will use the MONAI loader)\nimport random\n\nclass ToyDataLoader:\n    def __init__(self, dataset, batch_size=1, shuffle=False):\n        #CODE\n        #CODE\n        #CODE\n\n    def __iter__(self):\n        self.indices = #CODE -> set the indices starting from dataset\n\n        #CODE -> shuffle the indices, if necessary\n\n        self.current = #CODE\n        return self\n\n    def __next__(self):\n        if #CODE:\n            raise StopIteration\n\n        batch_indices = #CODE\n        self.current += #CODE\n\n        batch = #CODE\n        return batch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T15:17:33.484064Z","iopub.execute_input":"2025-11-28T15:17:33.484297Z","iopub.status.idle":"2025-11-28T15:17:33.489935Z","shell.execute_reply.started":"2025-11-28T15:17:33.484278Z","shell.execute_reply":"2025-11-28T15:17:33.489084Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Try your dataset and loader\nds = SegmentationDataset([10, 20, 30, 40, 50])\nloader = ToyDataLoader(ds, batch_size=#CODE, shuffle=#CODE)\n\nfor batch in loader:\n    print(batch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T10:47:35.778603Z","iopub.execute_input":"2025-11-27T10:47:35.778828Z","iopub.status.idle":"2025-11-27T10:47:35.794041Z","shell.execute_reply.started":"2025-11-27T10:47:35.778804Z","shell.execute_reply":"2025-11-27T10:47:35.793539Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transforms","metadata":{}},{"cell_type":"code","source":"# Check https://monai-dev.readthedocs.io/en/stable/transforms.html\nfrom monai.transforms import (\n    #CODE\n    #CODE\n    #CODE\n    #CODE\n    #CODE\n    #CODE\n)\n\n# Select a size\nPATCH_SIZE = #CODE\n\ntrain_transforms = Compose(\n    [\n        # First: load the image in dictionary form\n        #CODE\n\n        # Then, ensure the correct shape -> (W,H)\n        #CODE\n        #CODE\n        #CODE\n\n        # Now you can use some transformations\n\n        #CODE\n        #CODE\n        #CODE\n\n        #CODE\n        #CODE\n        #CODE\n\n        #CODE\n        #CODE\n        #CODE\n\n        #CODE\n        #CODE\n        #CODE\n\n        # And finlly transform the image and labels into a tensor\n        #CODE\n    ]\n)\n\n# The same goes for validation transformations:\nval_transforms = Compose([\n    #CODE\n    #CODE\n    #CODE\n\n    #CODE\n    #CODE\n    #CODE\n\n    #CODE\n    #CODE\n    #CODE\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T15:23:59.487063Z","iopub.execute_input":"2025-11-28T15:23:59.487804Z","iopub.status.idle":"2025-11-28T15:23:59.495205Z","shell.execute_reply.started":"2025-11-28T15:23:59.487776Z","shell.execute_reply":"2025-11-28T15:23:59.494308Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from monai.utils import first, set_determinism\n\nset_determinism(seed=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T10:48:08.28931Z","iopub.execute_input":"2025-11-27T10:48:08.289726Z","iopub.status.idle":"2025-11-27T10:48:08.299166Z","shell.execute_reply.started":"2025-11-27T10:48:08.289705Z","shell.execute_reply":"2025-11-27T10:48:08.298343Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from monai.data import CacheDataset, DataLoader, decollate_batch\n\n# Here check if your transforms are working correctly, using your Dataset class and\n# MONAI's DataLoader\ncheck_dataset = #CODE\ncheck_loader = #CODE\ncheck_data = #CODE\nimage, label = #CODE\nprint(f\"image shape: {image.shape}, label shape: {label.shape}\")\n\nplt.figure(\"check\", (12, 6))\nplt.subplot(1, 2, 1)\nplt.title(\"image\")\nplt.imshow(image[:, :], cmap=\"gray\")\nplt.subplot(1, 2, 2)\nplt.title(\"label\")\nplt.imshow(label[:, :], cmap=\"gray\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T10:48:08.300024Z","iopub.execute_input":"2025-11-27T10:48:08.300354Z","iopub.status.idle":"2025-11-27T10:48:09.370063Z","shell.execute_reply.started":"2025-11-27T10:48:08.300324Z","shell.execute_reply":"2025-11-27T10:48:09.369403Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"from monai.networks.nets import UNet\nfrom monai.networks.layers import Norm\nimport torch\n\n# Set the device for the model\ndevice = torch.device(\"cuda:0\")\n\n# Now we need a NN for 2D images segmentation:\n# we will use a MONAI UNet -> check https://monai-dev.readthedocs.io/en/fixes-sphinx/networks.html\nmodel = UNet(\n    # Image dimensions\n    spatial_dims= #CODE,\n    \n    # How many input channels?\n    in_channels= #CODE,\n    \n    # How many output channels? (That is, how many classes to recognize?)\n    out_channels= #CODE,\n    \n    # Feature maps at each level of the net\n    channels= #CODE,\n    \n    # Downsampling factors at each level\n    strides= #CODE,\n\n    # Number of residual blocks\n    num_res_units= #CODE,\n\n    # Normalization to be used  after convolutions\n    norm= #CODE,\n).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T10:48:09.37092Z","iopub.execute_input":"2025-11-27T10:48:09.371231Z","iopub.status.idle":"2025-11-27T10:48:09.537723Z","shell.execute_reply.started":"2025-11-27T10:48:09.371207Z","shell.execute_reply":"2025-11-27T10:48:09.537081Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loss function","metadata":{}},{"cell_type":"code","source":"from monai.metrics import #CODE\nfrom monai.losses import #CODE\n\n# Now we need to define a Loss Function: see https://monai.readthedocs.io/en/1.4.0/losses.html\nloss_function = #CODE\n\n# Optimizer...\noptimizer = #CODE\n\n# ...and here we define a suitble metric to evaluate the segmentation: see https://monai-dev.readthedocs.io/en/fixes-sphinx/metrics.html\ndice_metric = #CODE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T10:48:09.538481Z","iopub.execute_input":"2025-11-27T10:48:09.538734Z","iopub.status.idle":"2025-11-27T10:48:09.543708Z","shell.execute_reply.started":"2025-11-27T10:48:09.538711Z","shell.execute_reply":"2025-11-27T10:48:09.5431Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train and validation sets","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# We need to split our dataset_files in train and validation files\ntrain_files, val_files = #CODE\nprint(len(train_files), len(val_files))\n\n# Now, since we created a specific SegmentationDataset class, let's use it\n# we need to extract the data from train and validation files applying transformations;\n# then we need to load the data with DataLoader\ntrain_dataset= #CODE\ntrain_loader = #CODE\n\n\nval_ds = #CODE\nval_loader = #CODE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T10:49:36.223273Z","iopub.execute_input":"2025-11-27T10:49:36.223904Z","iopub.status.idle":"2025-11-27T10:49:36.229713Z","shell.execute_reply.started":"2025-11-27T10:49:36.223881Z","shell.execute_reply":"2025-11-27T10:49:36.229085Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training loop","metadata":{}},{"cell_type":"code","source":"# We will need to save our model, so let's create our checkpoint_directory\ncheckpoint_dir = BASE_DIR / \"models\"\ncheckpoint_dir.mkdir(exist_ok=True, parents=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T10:49:38.375588Z","iopub.execute_input":"2025-11-27T10:49:38.376196Z","iopub.status.idle":"2025-11-27T10:49:38.379779Z","shell.execute_reply.started":"2025-11-27T10:49:38.376174Z","shell.execute_reply":"2025-11-27T10:49:38.379099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Finally, the training loop\n\nmax_epochs = #CODE\nval_interval = 1\nbest_metric = -1\nbest_metric_epoch = -1\nepoch_loss_values = []\nmetric_values = []\n#CODE\n#CODE\n\nfor epoch in range(max_epochs):\n    #CODE\n    #CODE\n    #CODE\n    #CODE\n    #CODE\n    #CODE\n    #CODE\n    #CODE\n    #CODE\n    #CODE\n    .\n    .\n    .\n    #CODE\n    #CODE\n    #CODE\n    #CODE\n    #CODE\n    #CODE\n    #CODE\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T15:37:14.872224Z","iopub.execute_input":"2025-11-28T15:37:14.872858Z","iopub.status.idle":"2025-11-28T15:37:14.877701Z","shell.execute_reply.started":"2025-11-28T15:37:14.872818Z","shell.execute_reply":"2025-11-28T15:37:14.876903Z"},"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(\"train\", (12, 6))\nplt.subplot(1, 2, 1)\nplt.title(\"Epoch Average Loss\")\nx = [i + 1 for i in range(len(epoch_loss_values))]\ny = epoch_loss_values\nplt.xlabel(\"epoch\")\nplt.plot(x, y)\nplt.subplot(1, 2, 2)\nplt.title(\"Val Mean Dice\")\nx = [val_interval * (i + 1) for i in range(len(metric_values))]\ny = metric_values\nplt.xlabel(\"epoch\")\nplt.plot(x, y)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T10:54:25.567593Z","iopub.execute_input":"2025-11-27T10:54:25.567822Z","iopub.status.idle":"2025-11-27T10:54:25.825455Z","shell.execute_reply.started":"2025-11-27T10:54:25.567801Z","shell.execute_reply":"2025-11-27T10:54:25.824689Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from scipy.ndimage import rotate\n\n# Here you can load the model and check whether the predicted mask superimposes\n# correctly with initial image\n#CODE\n#CODE\n\nwith torch.no_grad():\n    for i, val_data in enumerate(val_loader):\n        #CODE\n        #CODE\n        #CODE\n        #CODE\n        #CODE\n\n        # Plot results\n        plt.figure(figsize=(15, 5))\n        plt.subplot(1, 3, 1)\n        plt.title(\"Original Image\")\n        plt.imshow()\n\n        plt.subplot(1, 3, 2)\n        plt.title(\"Ground Truth\")\n        plt.imshow()\n        plt.imshow()\n\n        plt.subplot(1, 3, 3)\n        plt.title(\"Prediction Overlay\")\n        plt.imshow()\n        plt.axis(\"off\")\n\n        plt.show()\n\n        if i == 2:\n            break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T15:43:00.462780Z","iopub.status.idle":"2025-11-28T15:43:00.463065Z","shell.execute_reply.started":"2025-11-28T15:43:00.462925Z","shell.execute_reply":"2025-11-28T15:43:00.462938Z"}},"outputs":[],"execution_count":null}]}